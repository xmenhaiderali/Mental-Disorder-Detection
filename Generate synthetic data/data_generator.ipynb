{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d92fca-63e3-4c63-90b6-ddf30796c11d",
   "metadata": {},
   "source": [
    "# Data Generation using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9ae594-cc29-45fa-985a-1965aec8ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate,PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import openai\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5960ab96-58aa-4b76-a4b5-49cbaa237fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, llm_model=\"gpt-4o\"):\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
    "    response =client.chat.completions.create(model=llm_model,\n",
    "                                           messages = messages,\n",
    "                                           )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d20576-69b5-48a3-857a-471fb8f7443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_data(data: pd.DataFrame, \n",
    "                       category:str,\n",
    "                       use_samples: int,\n",
    "                       number_of_tweets: int,\n",
    "                      llm_model=\"gpt-4o-mini\"):\n",
    "    data = data[data[\"tweet\"]!=\"\"]\n",
    "    cat_data = data[data[\"Disorder\"]==category]\n",
    "    cat_data.reset_index(drop=True,inplace=True)\n",
    "    samples = np.random.choice(range(len(cat_data)),use_samples,replace=False)\n",
    "    cat_data = cat_data.filter(items=samples, axis=0)\n",
    "    tweets = cat_data[\"tweet\"].values.tolist()\n",
    "    tweets = \"\\n\".join(tweets)\n",
    "    prompt = f\"\"\"Given the following tweets:\\n\\n{tweets}\\n\\nGenerate `{number_of_tweets}` more unique tweets \n",
    "                using above tweets. Generated `{number_of_tweets}` tweets should be different from above tweets.\n",
    "                `Do not add any extra text except tweets`\"\"\"\n",
    "    prompt = prompt.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    prompt_template = PromptTemplate(input_variables=[\"tweet\"], template=prompt)\n",
    "    response = get_completion(prompt,llm_model=llm_model)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "572fcc4f-ddff-4d23-8e5c-3fbb53db020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent/\"Data\"\n",
    "final_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "955ec555-1459-428d-967c-a70e46babb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 622/622 [00:06<00:00, 89.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 124/124 [00:01<00:00, 95.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 94.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 136/136 [00:01<00:00, 98.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████| 1703/1703 [00:25<00:00, 65.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 249/249 [00:02<00:00, 100.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 84.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 78.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 127/127 [00:01<00:00, 89.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 94.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for child in data_path.iterdir():\n",
    "    for child_ch in child.iterdir():\n",
    "        if child_ch.is_dir():\n",
    "            files = list(child_ch.glob(\"**/*.csv\"))\n",
    "            for fls in tqdm(range(len(files))):\n",
    "                df = pd.read_csv(files[fls])\n",
    "        else:\n",
    "            df = pd.read_csv(child_ch)\n",
    "        final_data = pd.concat([df,final_data],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64be1e31-d597-435a-80b0-8d8f7161f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data[[\"class\",\"tweet\"]]\n",
    "final_data.rename(columns={\"class\":\"Disorder\"}, inplace=True)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca40fc-b8b8-41cb-9eaa-3cc0676b815e",
   "metadata": {},
   "source": [
    "# Binary-class samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86c20058-8361-446a-bf06-cc3fdd9aa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_samples = (final_data[\"Disorder\"].value_counts().sum()-final_data[\"Disorder\"].value_counts()[\"CONTROL\"]) - \\\n",
    "                                                        final_data[\"Disorder\"].value_counts()[\"CONTROL\"]\n",
    "use_samples = 200\n",
    "generate_samples = 100\n",
    "for samples in tqdm(range(binary_samples//generate_samples)):\n",
    "    generated_data = generate_text_data(final_data,\"CONTROL\",use_samples,generate_samples)\n",
    "    generated_df = pd.DataFrame(data={\"tweet\":generated_data.split(\"\\n\")})\n",
    "    generated_df[\"Disorder\"]=\"CONTROL\"\n",
    "    final_data = pd.concat([final_data,generated_df], axis=0)\n",
    "    final_data = final_data.sample(len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdec816d-1a5c-4fa4-b670-45666529fe16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Disorder\n",
       "ADHD               3034\n",
       "SCHIZOPHRENIA      2970\n",
       "OCD                2905\n",
       "ANXIETY            2729\n",
       "CONTROL            2631\n",
       "PTSD               2466\n",
       "DEPRESSION         2161\n",
       "AUTISM             1425\n",
       "EATING DISORDER     403\n",
       "BIPOLAR             244\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.Disorder.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b45f2-6f84-4e2c-a17d-637ef3bc04db",
   "metadata": {},
   "source": [
    "# Multi-class samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e970ab54-cddc-4ce6-934f-0900180dd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = x[x[\"Disorder\"].isin([\"AUTISM\"])]\n",
    "final_data.Disorder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e753be76-3207-4fdb-a7c0-c15246d97da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTISM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 28/28 [09:46<00:00, 20.94s/it]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5000\n",
    "multi_class_samples = final_data[\"Disorder\"].value_counts().to_dict()\n",
    "out_of_band_samples = dict()\n",
    "for cls,samples in multi_class_samples.items():\n",
    "    if cls!=\"CONTROL\":\n",
    "        print(cls)\n",
    "        out_of_band_samples.update({cls:num_samples-multi_class_samples[cls]})\n",
    "        for samples in tqdm(range(out_of_band_samples[cls]//generate_samples)):\n",
    "            generated_data = generate_text_data(final_data,cls,use_samples,generate_samples)\n",
    "            generated_df = pd.DataFrame(data={\"tweet\":generated_data.split(\"\\n\")})\n",
    "            generated_df[\"Disorder\"]=cls\n",
    "            final_data = pd.concat([final_data,generated_df], axis=0)\n",
    "            final_data = final_data.sample(len(final_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c211d95a-cb12-43f3-8dfa-c105c6f3a047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AUTISM': 2840}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_band_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "daec4874-8fb1-41d8-a8e0-e4a1ec6cc201",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"multi_class_data_balanced.csv\")\n",
    "final_data.reset_index(drop=True,inplace=True)\n",
    "y = pd.concat([x,final_data], axis=0)\n",
    "y = y.sample(len(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
